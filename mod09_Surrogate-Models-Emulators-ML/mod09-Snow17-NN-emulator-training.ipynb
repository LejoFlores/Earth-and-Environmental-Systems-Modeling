{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
    "\n",
    "param_file = 'Snow17_NN_params.csv'\n",
    "SWE_sim_file = 'Snow17_NN_SWE.csv'\n",
    "forcing_file = 'Snow17_NN_forcing.csv'\n",
    "\n",
    "date_beg_train = '2012-10-01' # This is the first day of water year 2010\n",
    "date_end_train = '2015-09-30' # This is the last day of water year 2015\n",
    "\n",
    "date_beg_test = '2015-10-01' # This is the first day of water year 2016\n",
    "date_end_test = '2020-09-30' # This is the last day of water year 2020\n",
    "\n",
    "Nens_train = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split Training and Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nt_train = 1826\n",
      "Nt_test = 1827\n",
      "Nreps = 50\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "df_params = pd.read_csv(param_file)\n",
    "\n",
    "# Ensemble SWE simulation\n",
    "df_swe_sim = pd.read_csv(SWE_sim_file)\n",
    "df_swe_sim['Date'] = pd.to_datetime(df_swe_sim['Date'],format='%Y-%m-%d')\n",
    "df_swe_sim.index = df_swe_sim['Date']\n",
    "\n",
    "df_swe_sim_train = df_swe_sim[date_beg_train:date_end_train]\n",
    "df_swe_sim_test = df_swe_sim[date_beg_test:date_end_test]\n",
    "\n",
    "Nt_train = df_swe_sim_train.shape[0]\n",
    "Nt_test = df_swe_sim_test.shape[0]\n",
    "\n",
    "## Forcing\n",
    "df_forcing = pd.read_csv(forcing_file)\n",
    "df_forcing['Date'] = pd.to_datetime(df_forcing['Date'],format='%Y-%m-%d')\n",
    "df_forcing.index = df_forcing['Date']\n",
    "\n",
    "df_forcing_train = df_forcing[date_beg_train:date_end_train]\n",
    "df_forcing_test = df_forcing[date_beg_test:date_end_test]\n",
    "\n",
    "Nreps = Nens_train\n",
    "\n",
    "print('Nt_train = '+str(Nt_train))\n",
    "print('Nt_test = '+str(Nt_test))\n",
    "print('Nreps = '+str(Nreps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Assemble Training and Test Datasets Into Correct Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of SWE ensemble simulation - training: (91300, 1)\n",
      "Shape of SWE ensemble simulation - test:(91350, 1)\n"
     ]
    }
   ],
   "source": [
    "# Process our \"Obervations\" we want the neural net to predict. In this case SWE\n",
    "# Get the SWE ensemble and reshape it into a 1-D array, column-wise \n",
    "\n",
    "## TRAINING DATA\n",
    "SWE_ens_train = df_swe_sim_train.iloc[:,2:(Nreps+2)].values\n",
    "SWE_ens_1D_train = SWE_ens_train.T.reshape(Nt_train*Nreps,1)\n",
    "\n",
    "print('Shape of SWE ensemble simulation - training: '+str(SWE_ens_1D_train.shape))\n",
    "\n",
    "## TESTING DATA\n",
    "SWE_ens_test = df_swe_sim_test.iloc[:,2:(Nreps+2)].values\n",
    "SWE_ens_1D_test = SWE_ens_test.T.reshape(Nt_test*Nreps,1)\n",
    "\n",
    "print('Shape of SWE ensemble simulation - test:'+str(SWE_ens_1D_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tair_ens_train = (91300, 1)\n",
      "Shape of pcp_ens_train = (91300, 1)\n",
      "Shape of tair_ens_test = (91350, 1)\n",
      "Shape of pcp_ens_test = (91350, 1)\n"
     ]
    }
   ],
   "source": [
    "# Process our forcings, making a copy for each ensemble member\n",
    "## TRAINING DATA\n",
    "tair_train = df_forcing_train['tair'].values.reshape((Nt_train,1))\n",
    "tair_ens_train = np.tile(tair_train,(Nreps,1))\n",
    "print('Shape of tair_ens_train = '+str(tair_ens_train.shape))\n",
    "\n",
    "pcp_train = df_forcing_train['pcp'].values.reshape((Nt_train,1))\n",
    "pcp_ens_train = np.tile(pcp_train,(Nreps,1))\n",
    "print('Shape of pcp_ens_train = '+str(pcp_ens_train.shape))\n",
    "\n",
    "## TESTING DATA\n",
    "tair_test = df_forcing_test['tair'].values.reshape((Nt_test,1))\n",
    "tair_ens_test = np.tile(tair_test,(Nreps,1))\n",
    "print('Shape of tair_ens_test = '+str(tair_ens_test.shape))\n",
    "\n",
    "pcp_test = df_forcing_test['pcp'].values.reshape((Nt_test,1))\n",
    "pcp_ens_test = np.tile(pcp_test,(Nreps,1))\n",
    "print('Shape of pcp_ens_test = '+str(pcp_ens_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dd_ens_train = (91300, 1)\n",
      "Shape of Tt_ens_train = (91300, 1)\n",
      "Shape of Dd_ens_test = (91350, 1)\n",
      "Shape of Tt_ens_test = (91350, 1)\n"
     ]
    }
   ],
   "source": [
    "# Process our parameters making a copy for each date\n",
    "## TRAINING DATA\n",
    "Dd = df_params['Dd_ens'].iloc[0:Nreps].values.reshape((1,Nreps))\n",
    "Dd_ens_train = np.tile(Dd,(Nt_train,1)).T.reshape((Nt_train*Nreps,1))\n",
    "\n",
    "Tt = df_params['Tt_ens'].iloc[0:Nreps].values.reshape((1,Nreps))\n",
    "Tt_ens_train = np.tile(Tt,(Nt_train,1)).T.reshape((Nt_train*Nreps,1))\n",
    "\n",
    "print('Shape of Dd_ens_train = '+str(Dd_ens_train.shape))\n",
    "print('Shape of Tt_ens_train = '+str(Tt_ens_train.shape))\n",
    "\n",
    "## TESTING DATA\n",
    "Dd_ens_test = np.tile(Dd,(Nt_test,1)).T.reshape((Nt_test*Nreps,1))\n",
    "Tt_ens_test = np.tile(Tt,(Nt_test,1)).T.reshape((Nt_test*Nreps,1))\n",
    "\n",
    "print('Shape of Dd_ens_test = '+str(Dd_ens_test.shape))\n",
    "print('Shape of Tt_ens_test = '+str(Tt_ens_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWE_predictors_train dimensions = (91300, 4)\n",
      "SWE_predictors_test dimensions = (91350, 4)\n"
     ]
    }
   ],
   "source": [
    "# Assemble predictor array - training data\n",
    "SWE_predictors_train = np.concatenate((pcp_ens_train,tair_ens_train,Dd_ens_train,Tt_ens_train),axis=1)\n",
    "print('SWE_predictors_train dimensions = '+str(SWE_predictors_train.shape))\n",
    "\n",
    "# Assemble predictor array - test data\n",
    "SWE_predictors_test = np.concatenate((pcp_ens_test,tair_ens_test,Dd_ens_test,Tt_ens_test),axis=1)\n",
    "print('SWE_predictors_test dimensions = '+str(SWE_predictors_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "kernel = C(1.0, (1e-4, 1e1)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) + WhiteKernel(noise_level=1)\n",
    "\n",
    "# Initialize scalers\n",
    "scaler_predictors = MinMaxScaler()\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "# Scale the training and testing predictor data\n",
    "SWE_predictors_train_scaled = scaler_predictors.fit_transform(SWE_predictors_train)\n",
    "SWE_predictors_test_scaled = scaler_predictors.transform(SWE_predictors_test)\n",
    "\n",
    "# Scale the target variable (SWE)\n",
    "SWE_ens_1D_train_scaled = scaler_target.fit_transform(SWE_ens_1D_train)\n",
    "SWE_ens_1D_test_scaled = scaler_target.transform(SWE_ens_1D_train)\n",
    "\n",
    "# clf = MLPRegressor(hidden_layer_sizes=(10,10),\n",
    "#                    activation='relu',\n",
    "#                    learning_rate_init=0.001,\n",
    "#                    random_state=1,\n",
    "#                    max_iter=2000,\n",
    "#                    solver='adam').fit(SWE_predictors_train_scaled, SWE_ens_train_scaled.ravel())\n",
    "\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,\n",
    "                               n_restarts_optimizer=10,\n",
    "                               normalize_y=True)\n",
    "\n",
    "# Fit the GPR model with the scaled data\n",
    "gpr.fit(SWE_predictors_train_scaled, SWE_ens_1D_train_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "swe_ens_1D_predict_test_scaled = clf.predict(SWE_predictors_test_scaled)\n",
    "\n",
    "# Inverse transform the predictions to original scale\n",
    "swe_ens_1D_predict_test = scaler_target.inverse_transform(swe_ens_1D_predict_test_scaled.reshape(-1, 1))\n",
    "\n",
    "#swe_ens_1D_predict_test = clf.predict(SWE_predictors_test)\n",
    "print(swe_ens_1D_predict_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swe_ens_predict_test = swe_ens_1D_predict_test.reshape((Nt_test,Nreps))\n",
    "print(swe_ens_predict_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = 1\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.plot(df_forcing_test['Date'],swe_ens_predict_test[:,ens],label=['Emulator, ensemble member'+str(ens)])\n",
    "plt.plot(df_forcing_test['Date'],SWE_ens_test[:,ens],label=['Snow 17, ensemble member'+str(ens)])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('SWE [mm]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "swe_ens_1D_predict_train_scaled = clf.predict(SWE_predictors_train_scaled)\n",
    "\n",
    "swe_ens_1D_predict_train = scaler_target.inverse_transform(swe_ens_1D_predict_train_scaled.reshape(-1,1))\n",
    "\n",
    "swe_ens_predict_train = swe_ens_1D_predict_train.reshape((Nt_train,Nreps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(swe_ens_predict_train[:,200])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
