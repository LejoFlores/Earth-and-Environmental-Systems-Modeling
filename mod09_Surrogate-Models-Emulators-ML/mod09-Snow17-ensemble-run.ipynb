{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 09: Model Emulation, Part 1: Ensemble Simulation\n",
    "\n",
    "### 1. Introduction and Background\n",
    "\n",
    "So, in our model for this week, there will be two parameters that require calibration:\n",
    "* $T_t$: The threshold temperature used to decide whether precipitation is snow or if snowmelt is occuring, and\n",
    "* $D_D$: The degree-day factor that will translate positive air temperature departures from $T_t$ into snowmelt rates\n",
    "\n",
    "The system that we're modeling will be the East River Watershed in western Colorado, the site of a [major Earth science community effort to understand watershed function](https://watershed.lbl.gov/). We will use our model to make predictions of snow water equivalent (SWE) that we will compare against observed observations of SWE from a Snotel station within the watershed that has historically served as a good approximation of the total SWE within the watershed. We will compute a few error statistics relative to the observed historical values of SWE. We have 20 years of forcing data, but will only examine the last 5 years of the record.  \n",
    "\n",
    "### 2. `Python` Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# This is a new, but powerful library for time series analysis and handling real-world dates\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import qmc\n",
    "\n",
    "# The name of file that contains forcing and observed SWE during every day of water year 2001-2020\n",
    "forcing_fname = 'EastRiver_hydro_data_2001-2020.csv'\n",
    "\n",
    "date_beg = '2000-10-01' # This is the first day of water year 2000\n",
    "date_end = '2015-09-30' # This is the last day of water year 2000\n",
    "\n",
    "dt = 1 # Time step [day]\n",
    "\n",
    "Nreps = 1000 # Number of replicates\n",
    "\n",
    "DD_l = 1.0 # Lower bound of degree-day factor [mm/day/°C]\n",
    "DD_u = 10.5 # Upper bound of degree-day factor [mm/day/°C]\n",
    "Tt_l = -1.0 # Lower bound of temperature threshold [°C] \n",
    "Tt_u = 7.0 # Upper bound of temperature threshold [°C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = qmc.LatinHypercube(d=2)\n",
    "sample = sampler.random(Nreps)\n",
    "\n",
    "l_bounds = [DD_l, Tt_l]\n",
    "u_bounds = [DD_u, Tt_u]\n",
    "\n",
    "sample_scaled = qmc.scale(sample, l_bounds, u_bounds)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(sample_scaled[:,0],sample_scaled[:,1],'k.')\n",
    "plt.xlabel('Degree Day Factor [mm/day/°C]')\n",
    "plt.ylabel('Temperature Threshold [°C]')\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read Forcing Data and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the forcing data data\n",
    "df_forcing = pd.read_csv(forcing_fname)\n",
    "\n",
    "# Reindex to create make sure that the index for the dataframe is a datetime64 object\n",
    "df_forcing['Date'] = pd.to_datetime(df_forcing['Date'],format='%Y-%m-%d')\n",
    "df_forcing.index = df_forcing['Date']\n",
    "\n",
    "# Here's what a pandas \"dataframe\" looks like:\n",
    "df_forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature and precipitation during the period\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.bar(df_forcing['Date'][date_beg:date_end].values,df_forcing['pcp'][date_beg:date_end].values)\n",
    "plt.ylabel('Precipitation [mm/day]')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(df_forcing['Date'][date_beg:date_end].values,df_forcing['tair'][date_beg:date_end].values)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Air Temperature [°C]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Get Precipitation and Temperature Forcing Data \n",
    "\n",
    "Here we use our new `pandas` skills to get the values of the dates, precipitation, and temperature that coincide with the dates that we want to simulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ForcingDates = df_forcing[date_beg:date_end]['Date'].values\n",
    "P = df_forcing[date_beg:date_end]['pcp'].values\n",
    "Ta = df_forcing[date_beg:date_end]['tair'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Containers for Modeled Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.date_range(start=date_beg, end=date_end, freq='1D')\n",
    "Nt = t.size\n",
    "\n",
    "SWE = np.zeros((Nt,Nreps))\n",
    "Sm = np.zeros((Nt,Nreps))\n",
    "Pliq = np.zeros((Nt,Nreps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run the Snow-17 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in np.arange(Nreps):\n",
    "\n",
    "    SWE_rep = np.zeros((Nt))\n",
    "    Sm_rep = np.zeros((Nt))\n",
    "    Pliq_rep = np.zeros((Nt))\n",
    "    \n",
    "    DD = sample_scaled[r,0]\n",
    "    Tt = sample_scaled[r,1]\n",
    "    \n",
    "    for i in np.arange(Nt):\n",
    "\n",
    "        P_i  = P[i] # The value of precipitation on this date\n",
    "        Ta_i = Ta[i] # The value of average air temperature on this date\n",
    "\n",
    "        # Initial conditions: we are starting when there should not be any appreciable snow in the watershed, \n",
    "        # so we will assume that SWE = 0. If you decide to run another date when there might be snow (e.g., Jan. 1)\n",
    "        # then you would need a more realistic value of SWE.\n",
    "        if(i==0):\n",
    "            SWE_i = 0.0 \n",
    "        else:\n",
    "            SWE_i = SWE_rep[i-1] # The initial SWE on these dates is simply the SWE from the day before. We will add snow or subtract melt.\n",
    "            \n",
    "        # If SWE is greater than zero, there *may* be snowmelt\n",
    "        if(SWE_i>0.0):\n",
    "            if(Ta_i>Tt): # If the air temperature is greater than the threshold, there **will** be melt\n",
    "                Sm_i = DD*(Ta_i-Tt) # Snowmelt via degree-day factor\n",
    "            else: # If the air temperature is below the threshold, there is no melt\n",
    "                Sm_i = 0.0 # No snowmelt if temperature does not exceed threshold\n",
    "        else: # If there is no SWE, by definition there is no snowmelt\n",
    "            Sm_i = 0.0\n",
    "        \n",
    "        # If there is precipitation, figure out its phase\n",
    "        if((P_i>0.0) and (Ta_i<=Tt)):\n",
    "            SWE_i += P_i # All precip will be added to SWE storage\n",
    "            Pliq_i = 0.0 # There is no liquid precipitation\n",
    "        elif((P_i>0.0) and (Ta_i>Tt)):\n",
    "            Pliq_i = P_i # All precipitation falls as liquid. NOTE: We are assuming rain does not melt snow!!!\n",
    "        else: # If there is no precipitation, there is nothing to accumulate\n",
    "            Pliq_i = 0.0\n",
    "        \n",
    "        SWE_rep[i] = np.max([SWE_i - Sm_i,0.0]) # Make sure we can only melt as much SWE as there is. This only matters at low SWE\n",
    "        Sm_rep[i] = Sm_i # Save the snowmelt... QUESTION: Is this something we can observe?!?!?!?!\n",
    "        Pliq_rep[i] = Pliq_i\n",
    "        \n",
    "    SWE[:,r] = SWE_rep\n",
    "    Sm[:,r] = Sm_rep\n",
    "    Pliq[:,r] = Pliq_rep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.figure(figsize=(10,14))\n",
    "\n",
    "for r in np.arange(Nreps):\n",
    "    plt.subplot(2,1,1)\n",
    "    if r == 0:\n",
    "        plt.plot(t,SWE[:,r],'b-',label='Modeled SWE', linewidth=0.01)\n",
    "    else:\n",
    "        plt.plot(t,SWE[:,r],'b-', linewidth=0.01)\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    if r == 0:\n",
    "        plt.plot(t,Sm[:,r],'b-',label='Modeled Snowmelt', linewidth=0.01)\n",
    "    else:\n",
    "        plt.plot(t,Sm[:,r],'b-', linewidth=0.01)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(t,np.mean(SWE,1),'r-',label='Ensemble Mean', linewidth=2.0)\n",
    "plt.plot(t,df_forcing[date_beg:date_end]['SWE'].values,'k-',label='Observed SWE')\n",
    "plt.ylabel('Snow Water Equivalent [mm]')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(t,np.mean(Sm,1),'r-',label='Ensemble Mean', linewidth=2.0)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Modeled Snowmelt [mm/day]')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Save Results to a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SWE_sim = pd.DataFrame()\n",
    "df_SWE_sim['Dates'] = ForcingDates\n",
    "for r in np.arange(Nreps):\n",
    "    col_label = 'SWE rep '+str(r)\n",
    "    df_SWE_sim.insert(1,col_label,SWE[:,r])\n",
    "    df_SWE_sim = df_SWE_sim.copy() # Done to prevent fragmentation warning\n",
    "\n",
    "df_SWE_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Snow17_params = pd.DataFrame()\n",
    "df_Snow17_params['Dd_ens'] = sample_scaled[:,0]\n",
    "df_Snow17_params['Tt_ens'] = sample_scaled[:,1]\n",
    "df_Snow17_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SWE_sim.to_csv('Snow17_NN_SWE.csv')\n",
    "df_Snow17_params.to_csv('Snow17_NN_params.csv')\n",
    "df_forcing.to_csv('Snow17_NN_forcing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
