{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 08: Model Calibration â€“ Assignment\n",
    "\n",
    "In this assignment, you will extend the work we have done on model calibration to explore the following questions:\n",
    "\n",
    "1. When we calibrate the model on RMSE, how sensitive are our optimized parameters to our initial guess? And\n",
    "2. How different are the results when we calibrate the model on MAE? \n",
    "\n",
    "To address these questions, you will calibrate the model for four sets of initial guesses that correspond effectively to the four \"corners\" of our feasible space of parameters `DD` and `Tt`. You will plot the resulting calibrated values of these parameters to investigate the degree to which your calibrated parameters depend on where on the RMSE objective function surface you started. Then you'll repeat the analysis, but instead of calibrating to RMSE, you'll write code to calibrate the Snow-17 model to MAE. \n",
    "\n",
    "## 1. Notebook Setup\n",
    "\n",
    "Below we load the libraries we will need and initialize important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "import numbers\n",
    "\n",
    "# The name of file that contains forcing and observed SWE during every day of water year 2001-2020\n",
    "forcing_fname = 'EastRiver_hydro_data_2001-2020.csv'\n",
    "\n",
    "# The name of the file containing parameter combinations and associated KGE values from our\n",
    "# sensitivity analysis\n",
    "saved_error_metric_values_fname = 'Snow17_sensitivity_analysis.csv'\n",
    "\n",
    "date_beg = '2000-10-01' # This is the first day of water year 2016\n",
    "date_end = '2020-09-30' # This is the last day of water year 2020\n",
    "\n",
    "DD_i = np.array([2.0, 2.0, 9.0, 9.0]) # Initial guesses for degree-day factor\n",
    "Tt_i = np.array([0.0, 6.0, 6.0, 0.0]) # Initial guesses for temperature threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Forcing Data\n",
    "\n",
    "This data corresponds to the same East River watershed data we have been using throughout this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the forcing data data\n",
    "df_forcing = pd.read_csv(forcing_fname)\n",
    "\n",
    "# Reindex to create make sure that the index for the dataframe is a datetime64 object\n",
    "df_forcing['Date'] = pd.to_datetime(df_forcing['Date'],format='%Y-%m-%d')\n",
    "df_forcing.index = df_forcing['Date']\n",
    "\n",
    "ForcingDates = df_forcing[date_beg:date_end]['Date'].values\n",
    "P_exp = df_forcing[date_beg:date_end]['pcp'].values\n",
    "Ta_exp = df_forcing[date_beg:date_end]['tair'].values\n",
    "SWE_o = df_forcing[date_beg:date_end]['SWE'].values\n",
    "\n",
    "t = pd.date_range(start=date_beg, end=date_end, freq='1D')\n",
    "\n",
    "# Here's what a pandas \"dataframe\" looks like:\n",
    "df_forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Some Critical Functions\n",
    "\n",
    "### 3.1 Create a Function Defining the Snow-17 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Snow17(Ta,P,DD,Tt):\n",
    "    \n",
    "    assert Ta.shape == P.shape, 'Precipitation and Temperature vectors must have the same shape'\n",
    "    assert isinstance(DD, numbers.Number), 'Degree day coefficient must be a scalar'\n",
    "    assert isinstance(Tt, numbers.Number), 'Temperature threshold must be a scalar'\n",
    "\n",
    "    Nt = np.max(Ta.shape)\n",
    "    \n",
    "    SWE_s17 = np.zeros(Ta.shape)\n",
    "    Sm_s17 = np.zeros(Ta.shape)\n",
    "    Pliq_s17 = np.zeros(Ta.shape)\n",
    "    \n",
    "    for i in np.arange(Nt):\n",
    "\n",
    "        P_i  = P[i] # The value of precipitation on this date\n",
    "        Ta_i = Ta[i] # The value of average air temperature on this date\n",
    "\n",
    "        # Initial conditions: we are starting when there should not be any appreciable snow in the watershed, \n",
    "        # so we will assume that SWE = 0. If you decide to run another date when there might be snow (e.g., Jan. 1)\n",
    "        # then you would need a more realistic value of SWE.\n",
    "        if(i==0):\n",
    "            SWE_i = 0.0 \n",
    "        else:\n",
    "            SWE_i = SWE_s17[i-1] # The initial SWE on these dates is simply the SWE from the day before. We will add snow or subtract melt.\n",
    "            \n",
    "        # If SWE is greater than zero, there *may* be snowmelt\n",
    "        if(SWE_i>0.0):\n",
    "            if(Ta_i>Tt): # If the air temperature is greater than the threshold, there **will** be melt\n",
    "                Sm_i = DD*(Ta_i-Tt) # Snowmelt via degree-day factor\n",
    "            else: # If the air temperature is below the threshold, there is no melt\n",
    "                Sm_i = 0.0 # No snowmelt if temperature does not exceed threshold\n",
    "        else: # If there is no SWE, by definition there is no snowmelt\n",
    "            Sm_i = 0.0\n",
    "        \n",
    "        # If there is precipitation, figure out its phase\n",
    "        if((P_i>0.0) and (Ta_i<=Tt)):\n",
    "            SWE_i += P_i # All precip will be added to SWE storage\n",
    "            Pliq_i = 0.0 # There is no liquid precipitation\n",
    "        elif((P_i>0.0) and (Ta_i>Tt)):\n",
    "            Pliq_i = P_i # All precipitation falls as liquid. NOTE: We are assuming rain does not melt snow!!!\n",
    "        else: # If there is no precipitation, there is nothing to accumulate\n",
    "            Pliq_i = 0.0\n",
    "        \n",
    "        SWE_s17[i] = np.max([SWE_i - Sm_i,0.0]) # Make sure we can only melt as much SWE as there is. This only matters at low SWE\n",
    "        Sm_s17[i] = Sm_i # Save the snowmelt... QUESTION: Is this something we can observe?!?!?!?!\n",
    "        Pliq_s17[i] = Pliq_i\n",
    "        \n",
    "        \n",
    "    return SWE_s17, Sm_s17, Pliq_s17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create a Function to Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_m,y_o):\n",
    "    \n",
    "    # Inputs: \n",
    "    # y_m: Modeled time series\n",
    "    # y_o: Observed time series\n",
    "    \n",
    "    RMSE = np.sqrt(np.nanmean((y_m - y_o)**2))\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create an Objective Function Based on RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_rmse(params):\n",
    "    DD_exp, Tt_exp = params # Get DD and Tt parameters\n",
    "    \n",
    "    # 1. Call Snow-17 model \n",
    "    SWE_m, Sm_m, Pliq_m = Snow17(Ta_exp,P_exp,DD_exp,Tt_exp)\n",
    "    \n",
    "    # 2. Get RMSE value for simulated SWE\n",
    "    RMSE_exp = RMSE(SWE_m,SWE_o)\n",
    "\n",
    "    # 3. Return RMSE because the optimization function we're using seeks minimization\n",
    "    return RMSE_exp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calibrate on RMSE\n",
    "\n",
    "Below, find the lines with comments labelled `TODO:` and insert/modify the code appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ig = DD_i.size # The number of initial conditions being considered\n",
    "\n",
    "# TODO: Create containers to store optimized DD and Tt \n",
    "\n",
    "\n",
    "for i in np.arange(N_ig):\n",
    "    initial_guess = # TODO: Get the initial conditions for this combination\n",
    "\n",
    "    # Calibrate the model based on this initial guess\n",
    "    optimized_params_rmse = optimize.minimize(\n",
    "        objective_function_rmse,\n",
    "        initial_guess, \n",
    "        method='CG',\n",
    "        jac='3-point',\n",
    "        options={\n",
    "            'disp': True,\n",
    "            'maxiter': 2000,\n",
    "        }\n",
    "        )\n",
    "\n",
    "    # Print the values of the optimized parameters to the screen\n",
    "    print(\"Optimized Parameters:\", optimized_params_rmse.x)\n",
    "\n",
    "    # TODO: Store the calibrated parameters in the array you created above\n",
    "     = optimized_params_rmse.x[0]\n",
    "     = optimized_params_rmse.x[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 1. Read in the RMSE surface we created in the sensitivity analysis/brute force calibration notebook\n",
    "# 2. Use the contour() and contourf() to create a plot of the RMSE surface\n",
    "# 3. Plot the initial guesses on the plot as large Xs (see the markersize property in matplotlib)\n",
    "# 4. Plot the optimized guesses on the plot as large Os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Now Calibrate to MAE\n",
    "\n",
    "Now you will repeat the above analysis, but instead calibrate the model to the mean absolute error (MAE), an error metric we also examined in our sensitivity analysis. \n",
    "\n",
    "### 5.1 Define a Function to Calculate MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y_m,y_o):\n",
    "    # TODO: Add code here\n",
    "    \n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create an Objective Function Based on MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_mae(params):\n",
    "    # TODO: Get the parameters\n",
    "    \n",
    "    # TODO: Calculate SWE with input parameters\n",
    "    \n",
    "    # TODO: Call function to calculate MAE\n",
    "    \n",
    "    return MAE_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Calibrate the Model to MAE\n",
    "\n",
    "Use the code immediately below section 4 above to calibrate the model. Use the same 4 initial guesses we defined at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Insert code to call `optimize.minimize()` for each initial guess and using MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 1. Read in the MAE surface we created in the sensitivity analysis/brute force calibration notebook\n",
    "# 2. Use the contour() and contourf() to create a plot of the MAE surface\n",
    "# 3. Plot the initial guesses on the plot as large Xs \n",
    "# 4. Plot the optimized guesses on the plot as large Os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Reflection Questions\n",
    "\n",
    "Answer the following reflection questions:\n",
    "\n",
    "1. How sensitive are the optimized parameters to the initial guess? Did calibrating to MAE result in appreciably different results when compared to calibrating to RMSE? \n",
    "2. What are the implications of the above results? How would you coach a colleague who is considering creating a Snow-17 model for a different location in, for example, Washington or Idaho?\n",
    "3. How generalizable do you think your conclusions are for __*other*__ models? Based on what we've done in this module? How might you approach calibration of a model that is of a completely different process but of similar complexity? For example, say you needed to calibrate the advection-dispersion code to a time series of contaminant concentration in an observation well some known distance away from an oil spill with a known date?  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geos505",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
